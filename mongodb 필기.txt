1. mongodb를 이용한 분산 / 복제

(1) Master Slave 방식

	- 노드 3개 준비
		Master : port 10000
		Slave1 : port 10001
		Slave2 : port 10002

	- 3대의 서버 실행
		mongod --dbpath C:\mongowork\master --port 10000 --master
		mongod --dbpath C:\mongowork\slave1 --port 10001 --slave --source localhost:10000
		mongod --dbpath C:\mongowork\slave2 --port 10002 --slave --source localhost:10000

	- 3대의 클라이언트 준비
		mongo localhost:10000
		mongo localhost:10001
		mongo localhost:10002

	- master에서 작업
		show collections
		db.test.insert({a:1})
		db.test.find()

	- 각 slave에서 작업
		show collections

		db.setSlaveOk()
		show collections
		db.test.find()		
		db.test.insert({b:2})	

	- 첫번째 slave에 결함 생성
		slave1의 서버 중지
		slave의 db 삭제 (탐색기의 slave1 폴더 안 내용 다 삭제)

		slave 1 다시 가동
		mongod --dbpath C:\mongowork\slave1 --port 10001 --slave --source localhost:10000

		클라이언트 재접속
		mongo localhost:1001

(2) ReplicaSet
	
	- 4개의 서버 가동
		mongod --dbpath C:\mongowork\db1 --port 10001 --replSet rptmongo --oplogSize 10
		mongod --dbpath C:\mongowork\db2 --port 10002 --replSet rptmongo --oplogSize 10
		mongod --dbpath C:\mongowork\db3 --port 10003 --replSet rptmongo --oplogSize 10
		mongod --dbpath C:\mongowork\arbit --port 10004 --replSet rptmongo --oplogSize 10

	- primary로 지정한 client 접속(DB1을 지정할 것)
		mongo localhost:10001
		use admin

		db.runCommand(
			{"replSetInitiate" : {"_id" : "rptmongo", "members" : [ 
			{"_id" : 1, "host" : "localhost:10001"},
			{"_id" : 2, "host" : "localhost:10002"},
			{"_id" : 3, "host" : "localhost:10003"},
			{"_id" : 4, "host" : "localhost:10004", arbiterOnly : true}
			] }}
		)

	-primary에서 입력 테스트
		use test 
		db.test.insert({a:1})
		db.test.find()

	-secondary에서 테스트
		use test 
		db.setSlaveOk()
		db.test.find()
		db.test.insert({b:2})
		db.test.find()

	-arbiter에서 테스트
		use test 
		db.setSlaveOk()
		db.test.find()

	- primary 서버 장애
		primary 서버 중지
		primary db 삭제


2. mongodb를 이용한 분산

(1) config 서버 : ReplicaSet으로 구현 (3대)
	C:\mongowork\shared\config1
	C:\mongowork\shared\config2
	C:\mongowork\shared\config3

	mongod --configsvr --replSet configRepl --dbpath C:\mongowork\shared\config1 --port 20001
	mongod --configsvr --replSet configRepl --dbpath C:\mongowork\shared\config2 --port 20002
	mongod --configsvr --replSet configRepl --dbpath C:\mongowork\shared\config3 --port 20003

	-primary 설정
		20001 포트의 서버로 접속

		var config = {"_id" : "configRepl" , "members":[
				{"_id" : 1, "host" : "localhost:20001"},
				{"_id" : 2, "host" : "localhost:20002"},
				{"_id" : 3, "host" : "localhost:20003"} ]}

		rs.initiate(config)

(2) shard 서버

	C:\mongowork\shared\shard1\shardRep1
	C:\mongowork\shared\shard1\shardRep2
	C:\mongowork\shared\shard1\shardRep3

	C:\mongowork\shared\shard2\shardRep1
	C:\mongowork\shared\shard2\shardRep2
	C:\mongowork\shared\shard2\shardRep3

	C:\mongowork\shared\shard3\shardRep1
	C:\mongowork\shared\shard3\shardRep2
	C:\mongowork\shared\shard3\shardRep3

	mongod --shardsvr --replSet shardRep1 --dbpath C:\mongowork\shared\shard1\shardRep1 --port 30011
	mongod --shardsvr --replSet shardRep1 --dbpath C:\mongowork\shared\shard1\shardRep2 --port 30012
	mongod --shardsvr --replSet shardRep1 --dbpath C:\mongowork\shared\shard1\shardRep3 --port 30013

	mongod --shardsvr --replSet shardRep2 --dbpath C:\mongowork\shared\shard2\shardRep1 --port 30021
	mongod --shardsvr --replSet shardRep2 --dbpath C:\mongowork\shared\shard2\shardRep2 --port 30022
	mongod --shardsvr --replSet shardRep2 --dbpath C:\mongowork\shared\shard2\shardRep3 --port 30023

	mongod --shardsvr --replSet shardRep3 --dbpath C:\mongowork\shared\shard3\shardRep1 --port 30031
	mongod --shardsvr --replSet shardRep3 --dbpath C:\mongowork\shared\shard3\shardRep2 --port 30032
	mongod --shardsvr --replSet shardRep3 --dbpath C:\mongowork\shared\shard3\shardRep3 --port 30033

	-primary 설정
		mongo localhost:30011
		---------------------------
		var config = {"_id" : "shardRep1" , "members":[{"_id" : 1, "host" : "localhost:30011"},
			{"_id" : 2, "host" : "localhost:30012"},
			{"_id" : 3, "host" : "localhost:30013"} ]}

		rs.initiate(config)


		mongo localhost:30021
		---------------------------
		var config = {"_id" : "shardRep2" , "members":[{"_id" : 1, "host" : "localhost:30021"},
			{"_id" : 2, "host" : "localhost:30022"},
			{"_id" : 3, "host" : "localhost:30023"} ]}

		rs.initiate(config)


		mongo localhost:30031
		---------------------------
		var config = {"_id" : "shardRep3" , "members":[{"_id" : 1, "host" : "localhost:30031"},
			{"_id" : 2, "host" : "localhost:30032"},
			{"_id" : 3, "host" : "localhost:30033"} ]}

		rs.initiate(config)

(3) Route 서버
	- config 서버 등록
		mongos --configdb configRepl/localhost:20001,localhost:20002,localhost:20003

	- Route 서버에 접속
		mongo localhost:27017

	- shard서버 등록
		sh.addShard("shardRep1/localhost:30011")
		sh.addShard("shardRep2/localhost:30021")
		sh.addShard("shardRep3/localhost:30031")

	- DB 생성
		sh.enableSharding("test")

	- 인덱스 생성
		db.thing.createIndex({empno:1})

		use admin
		sh.shardCollection("test.thing", {empno:"hashed"})

	- Testing
		use test
		for(var n=100000; n<110000; n++){
			db.thing.insert({empno:n, ename:"test", sal:1000})
		}

		db.thing.count()

	- 각 shard서버에 접속해서 갯수 확인
		mongo localhost:30011
		use test
		db.thing.count()

		mongo localhost:30021
		use test
		db.thing.count()

		mongo localhost:30031
		use test
		db.thing.count()

2. HADOOP 실습
		*.hadoop 설치
		- hadoop 환경 설정
				gedit /etc/profile
				<텍스트 편집기 뜨면 맨 아래에 내용 추가>
				export HADOOP_HOME=/root/hadoop2
				export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin

				export HDFS_NAMENODE_USER="root"
				export HDFS_DATANODE_USER="root"
				export HDFS_SECONDARYNAMENODE_USER="root"
				export YARN_RESOURCEMANAGER_USER="root"
				export YARN_NODEMANAGER_USER="root"

				저장 후 재부팅
				hadoop version
				
		1. 독립모드
				터미널창에서 아래의 명령어를 실행(한줄로 이어서 실행)
				hadoop jar
				$HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples=2.10.0.jar wordcount $HADOOP_HOME/etc/hadoop/hadoop-env.sh wordcount_output
				
				hadoop을 실행한 위치에 wordcount_output폴더가 생성됨
				그 폴더 내부에 part-.... 을 gedit으로 읽어보자.
				
		2. 의사 분산 모드
				(1) 인증키 작성(비밀키와 공개키 생성)
						- 현재 위치가 home 디렉토리(root)인지 확인
						- ls -al 로 숨겨진 폴더나 파일까지 확인
								.ssh 폴더 확인하고 cd .ssh 로 이동
						- ssh-keygen -t rsa
						- 공개키를 상대 서버(slave)에 전송
								 cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
						- 다시 접속 테스트
								ssh localhost
				(2) hadoop 세팅
						- gedit $HADOOP_HOME/etc/hadoop/hadoop-env.sh
								export JAVA_HOME=/usr/local/jdk11
								
						- gedit $HADOOP_HOME/etc/hadoop/core-site.xml
								<configuration>
										<property>
												<name>fs.defaultFS</name>
												<value>hdfs://localhost:9000</value>
										</property>
								</configuration>
								
						- gedit $HADOOP_HOME/etc/hadoop/hdfs-site/xml
								<configuration>
										<property>
												<name>dfs.replication</name>
												<value>1</value>
										</property>
								</configuration>
				
				(3) 네임노드 포맷
						hdfs namenode -format
						
				(4) 하둡 클러스터 시작(하둡 분산 파일 시스템 시작)
						start-dfs.sh
				
				(5) jps로 프로세스 확인
						Jps
						NameNode
						DataNode
						SecondaryNameNode
						
				(6) 프로세스가 제대로 실행이 안될 경우
						stop-dfs.sh
						hdfs namenode -format
						start-dfs.sh
						jps
				
				(7) stop-dfs.sh

				(8) 모니터링
						- 로컬에서 확인 : http://localhost:50070
						- 원격으로 확인 : http://192.168.10.1:50070
								리눅스에서 방화벽 개방
								firewall-cmd --zone=public -add-port=50070/tcp --permanent
								firewall-cmd --reload
								
								virtualbox에서 포워딩
				
				(9) YARN 실행 : NodeManager, ResourceManager
						- start-yarn.sh     
						jps
				(10) ResourceManager를 모니터링
						- 로컬에서 확인 : http://localhost:8088
				(11) 종료
						- stop-dfs.sh
						jps
						- stop-yarn.sh
						jps
				(12) hdsf 활용
						- start-dfs.sh

						hdfs dfs -mkdir /user  <가상공간에 폴더 생성>	
						hdfs dfs -ls /

						hdfs dfs -mkdir /user/root
						hdfs dfs -mkdir /user/centos

						hdfs dfs mkdir /user/root/conf
						hdfs dfs -ls -R /
						
						현재 로컬에 있는 readme.txt파일을 hdfs로 업로드
						hdfs dfs -copyFromLocal $HADOOP_HOME/README.txt /user
						hdfs dfs -ls /user
						
						hadoop jar HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.10.0.jar wordcount /user/README.txt wordcount_output
						
						hdfs dfs -ls
						hdfs dfs -ls wordcount_output
						
						hdfs dfs -cat wordcount_output/part-r-00000
		
		3. 완전 분산 모드
				1) 시스템 구성
						host os : windows
						virtual machine : virtualbox
								- ip : 192.168.10.1
								- ip : 192.168.10.2
						guest os1 : master
								- ram : 2g
								- hdd : 30g
								- ip  : 10.0.2.15
								- ip  : 192.168.10.10
						guest os2 : slave1
								- ram : 1g
								- hdd : 30g
								- ip  : 192.168.10.11
						guest os3 : slave2
								- ram : 1g
								- hdd : 30g
								- ip  : 192.168.10.12
						guest os4 : slave3
								- ram : 1g
								- hdd : 30g
								- ip  : 192.168.10.13	
				
				2) master에 랜카드 하나 더 추가
						virtualbox 관리자 > 파일 > 호스트 네트워크 관리자 > 만들기
						
						- master에서 설정
								cd /etc/sysconfig/network-scripts/
								ll
								
								cat ifcfg-enp0s3
								
								gedit ifcfg-enp0s8
								---------------------
								DEVICE=enp0s8
								ONBOOT=yes
								BOOTPROTO=static
								IPADDR=192.168.10.10
								NETMASK=255.255.255.0
								
								systemctl restart network
								ifconfig
								
								나머지 slave들도 동일하게 설정(ip만 다르게)
								
						- ping 명령어로 확인
								master에서
										ping 192.168.10.11
										중지즌 ctrl + c
										ping 192.168.10.12
										
								slave1에서
										ping 192.168.10.10
										ping 192.168.10.12
										
								slave2에서
										ping 192.168.10.10
										ping 192.168.10.11
										
				3) 각 guest os의 host명을 변경
						gedit /etc/hosts
						--------------------------
						127.0.0.1 		localhost
						192.168.10.10 	master
						192.168.10.11 	slave1
						192.168.10.12 	slave2
						
				4) host와 hostname을 일치시키는 작업
						master에서	
								gedit /etc/hostname
								--------------------
								master
								--------------------
								
								/bin/hostname -F /etc/hostname
								reboot
						
						slave1에서	
								gedit /etc/hostname
								--------------------
								slave1
								--------------------
								
								/bin/hostname -F /etc/hostname
								reboot
						
						slave2에서	
								gedit /etc/hostname
								--------------------
								slave2
								--------------------
								
								/bin/hostname -F /etc/hostname
								reboot
								
						master에서 ping test
								ping slave1
								ping slave2
								
						root@master
						root@slave1
						root@slave2
								
				5) 인증키 전달
						master에서 
								ssh slave1
								exit
								ssh slave2
								exit
						
						나머지 slave에서도 동일하게 테스트
						
						만약 인증이 풀렸을 경우
						
						r : recursive : 하위 디렉토리 및 파일을모두 전송
						p : persistence : 원본파일 수정/사용시간 및 권한 유지함
						
						scp -rp ~/.ssh/authorized_keys >> root@slave1:~/.ssh/authorized_keys
						scp -rp ~/.ssh/authorized_keys >> root@slave2:~/.ssh/authorized_keys
						scp -rp ~/.ssh/authorized_keys >> root@slave3:~/.ssh/authorized_keys
				
				6) Hadoop 세팅
						a) hadoop-env.sh 수정(master에서만 실행)
								- gedit $HADOOP_HOME/etc/hadoop/hadoop-env.sh
										자바의 경로 수정
										
										export HADOOP_PID_DIR=/root/hadoop2/pids
						
						b) core-site.xml 수정(모든 노드에서 실행)
								- gedit $HADOOP_HOME/etc/hadoop/core-site.xml
										<configuration>
												<property>
														<name>fs.defaultFS</name>
														<value>hdfs://master:9000</value>
												</property>
										</configuration>
						
						c) hdfs-site 수정
								- master에서만 작업
										rm -rf $HADOOP_HOME/namenode
										mkdir $HADOOP_HOME/namenode
										cd $HADOOP_HOME/
										ls -l
										chown root -R $HADOOP_HOME/namenode
										chmod 777 $HADOOP_HOME/namenode
										
										rm -rf $HADOOP_HOME/datanode
										mkdir $HADOOP_HOME/datanode
										cd $HADOOP_HOME/
										ls -l
										chown root -R $HADOOP_HOME/datanode
										chmod 777 $HADOOP_HOME/datanode
										
								- 모든 slave에서 작업
										rm -rf $HADOOP_HOME/datanode
										mkdir $HADOOP_HOME/datanode
										cd $HADOOP_HOME/
										ls -l
										chown root -R $HADOOP_HOME/datanode
										chmod 777 $HADOOP_HOME/datanode
								
								- gedit $HADOOP_HOME/etc/hadoop/hdfs-site.xml
										<configuration>
												<property>
														<name>dfs.replication</name>
														<value>1</value>
												</property>
										</configuration>
								
								- gedit $HADOOP_HOME/etc/hadoop/hdfs-site.xml(master에서 작업)
										<configuration>
												<property>
														<name>dfs.replication</name>
														<value>2</value>
												</property> 
												<property>
														<name>dfs.permissions</name>
														<value>false</value>
												</property>
												<property>
														<name>dfs.namenode.dir</name>
														<value>file:/root/hadoop2/namenode</value>
												</property>
												<property>
														<name>dfs.datanode.data.dir</name>
														<value>file:/root/hadoop2/datanode</value>
												</property>
										</configuration>
							
								- gedit $HADOOP_HOME/etc/hadoop/hdfs-site.xml(slave1, 2 에서 작업)
										<configuration>
												<property>
														<name>dfs.replication</name>
														<value>2</value>
												</property>
												<property>
														<name>dfs.permissions</name>
														<value>false</value>
												</property>
												<property>
														<name>dfs.datanode.data.dir</name>
														<value>file:/root/hadoop2/datanode</value>
												</property>
										</configuration>
														
						d) Job Tracker 설정(모든 노드에서 작성)
								- mapred-site.xml 작성
										cd $HADOOP_HOME/etc/hadoop
										ls -l
										
										cp mapred-site.xml.template mapred-site.xml
																
										gedit mapred-site.xml
										-----------------------
										<configuration>
												<property>
														<name>mapreduce.framework.name</name>
														<value>yarn</value>
												</property>
										</configuration>
								
								- yarn-site.xml 작성
										gedit yarn-site.xml
										-------------------------
										<property>
												<name>yarn.nodemanager.aux-services</name>
												<value>mapreduce_shuffle</value>
										</property>
										<property>
												<name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
												<value>org.apache.hadoop.mapred.ShuffleHandler</value>
										</property>				
								
								scp -rp mapred-site.xml root@slave1:/root/hadoop2/etc/hadoop/mapred-site.xml         
								scp -rp yarn-site.xml root@slave1:/root/hadoop2/etc/hadoop/yarn-site.xml

								scp -rp mapred-site.xml root@slave2:/root/hadoop2/etc/hadoop/mapred-site.xml         
								scp -rp yarn-site.xml root@slave2:/root/hadoop2/etc/hadoop/yarn-site.xml            

								scp -rp mapred-site.xml root@slave3:/root/hadoop2/etc/hadoop/mapred-site.xml         
								scp -rp yarn-site.xml root@slave3:/root/hadoop2/etc/hadoop/yarn-site.xml
						
						e) masters, slaves 파일 편집(master에서만 작업)
								cd $HADOOP_HOME/etc/hadoop
								ls -l
								
								gedit masters
								----------------
								master
								
								gedit slaves
								----------------
								master
								slave1
								slave2
						f) 방화벽 내림(모든 노드)
								systemctl stop firewalld.service
								systemctl disable firewalld.service
								
						g) 네임노드 포맷, 하둡 가동(master에서만 작업)
								hdfs namenode -format
								start-dfs.sh
								start-yarn.sh
								jps
										master : NameNode, SecondaryNameNode, DataNode, ResourceManager, NodeManager
										slave : DataNode, NodeManager
						
						***. DataNode가 실행되지 않을 경우
								master에서
										stop-dfs.sh
										stop-yarn.sh
								
										rm -rf $HADOOP_HOME/namenode
										mkdir $HADOOP_HOME/namenode
										chown root -R $HADOOP_HOME/namenode
										chmod 777 $HADOOP_HOME/namenode
										
										rm -rf $HADOOP_HOME/datanode
										mkdir $HADOOP_HOME/datanode
										chown root -R $HADOOP_HOME/datanode
										chmod 777 $HADOOP_HOME/datanode
								
								slave 1, 2
										rm -rf $HADOOP_HOME/datanode
										mkdir $HADOOP_HOME/datanode
										chown root -R $HADOOP_HOME/datanode
										chmod 777 $HADOOP_HOME/datanode
						
								master에서
										hdfs namenode -format
										start-dfs.sh
										start-yarn.sh
						
						h) 하둡 시스템 가동
								master에서
										start-dfs.sh
										start-yarn.sh
										jps
								slave에서 
										jps
										
								master에서
										로컬에서는 http://master:50070
										원격으로는 http://192.168.10.1:50070
		
		4. 하둡 시스템 활용
				1) wordcount 라는 분석 프로그램 실행 
						hdfs dfs -mkdir /user
						hdfs dfs -mkdir /user/root
						hdfs dfs -mkdir /user/root/conf

						hdfs dfs ls -R /

						hdfs dfs -mkdir /upload
						hdfs dfs -copyFromLocal $HADOOP_HOME/README.txt /upload/README.txt
						(hdfs dfs -put $HADOOP_HOME/README.txt /upload/README.txt)

						hdfs dfs -ls /upload

						cd $HADOOP_HOME/share/hadoop/mapreduce
						ls -l

						hadoop jar hadoop-mapreduce-examples-2.10.0jar wordcount /upload/README.txt ~/wordcount_output
						
						- safe mode 에러 발생 시
								hdfs dfsadmin -safemode leave
						
						hdfs dfs -ls ~/wordcount_output
						
						hdfs dfs -cat ~/wordcount_output/part-r-00000
						
						- hdfs 로부터 다운로드
								hdfs dfs -get
								hdfs dfs -copyToLocal
								
								hdfs dfs -copyToLocal ~/wordcount_output/part-r-00000 ~\result.txt
								cd ~
								ls -l
				
				2) HDFS(Hadoop Distributed File System) : hdfs dfs -명령어
						a) 도움말
								hdfs dfs -help
								hdfs dfs -help copyToLocal
						
						b) 목록 조회
								hdfs dfs -ls
								hdfs dfs -ls 경로
								hdfs dfs -ls -R 경로 또는 hdfs dfs -lsr 경로
						
						c) 파일 용량 확인
								hdfs dfs -du /
								
						d) 파일 내용 보기 : cat, text
						
						e) 디렉토리 생성
								hdfs dfs -mkdir 디렉토리명
								
						f) 파일 복사
								- 업로드
										hdfs dfs -put
										hdfs dfs -copyFromLocal
										
								- 다운로드	
										hdfs dfs -get
										hdfs dfs -copyToLocal
										
								- 여러 개의 파일을 하나로 합쳐서 다운로드 : getmerge
										cd ~
										hdfs dfs -getmerge ~/wordcount_output result
										cat result
								- 파일 복사
										hdfs dfs -cp ~/wordcount_output/part-r-00000 /upload/part0
										hdfs dfs -ls /upload
										
								- 파일 이동
										hdfs dfs -mv 이동 전 경로 이동 후 경로
										hdfs dfs -moveFromLocal 로컬경로 hdfs경로
										
						g) 파일 삭제
								hdfs dfs -rm 파일
								hdfs dfs -rm -r 디렉토리
								hdfs dfs -rm -rf : 디렉토리 강제 삭제
								
						
						h) 카운트 값 조회
								hdfs dfs -count /upload
								hdfs dfs -count /
								--------------------------------
								디렉토리 갯수      파일의 갯수      파일 사이즈
                        
						i) 파일 내용 일부분 확인
								hdfs dfs -tail 파일명
								hdfs dfs -head 파일명
								hdfs dfs -cat 파일명 | head -10
								
						j) 권한 변경
								hdfs dfs -chmod 숫자 디렉토리 혹은 파일
						  
						k) 0바이트 파일 생성
								hdfs dfs -thouchz 파일명
										
				3) 자바 프로그래밍1 : HDFS 입출력 실습
						a) project type : java Project
						b) project name : Hadoop
						c) package name : hdfs
						d) outputs : Hadoop.jar
						e) Hadoop.jar를 리눅스 master 서버에 전송 (source 폴더 생성)
								cd /root/source
								hadoop jar Hadoop.jar hdfs.HdfsFile input.txt "Hello~~~, Hadoop"
								
								hdfs dfs -ls input.txt
								hdfs dfs -cat input.txt		
				4) 자바 프로그래밍2 : 단어의 빈도 수 계산 프로그램
						a) package name : count
						b) outputs : Hadoop.jar
						
						c) MapReduce 실행 방식
								맵 : (k1, v1) => list(k2, v2)
								리듀스 : (k2, list(v2)) => list3(k3, v3)
								
								- 입력 데이터
										read a book
										write a book
								
								- 맵으로 변환(key : line number, value : 문장)
										1, read a book
										2, write a book
								
								- 정렬과 병합 (key : 단어, value : 단어 수)
										<read, 1>
										<a, 1>
										<book, 1>
										<write, 1>
										<a, 1>
										<book, 1>
								
								- 리듀스 단계 : (key : 단어, value : 단어 수의 리스트)
										<read, (1)>
										<a, (1, 1)>
										<book, (1, 1)>
										<write, (1)>
										
								- 실행 결과 : (key : 단어, value : 리스트의 합계)
										<read, 1>
										<a, 2>
										<book, 2>
										<write, 1>
										
						d) 맵리듀스 프로그래밍 요소
								- 데이터 타입
										맵리듀스 프로그램에서 카와 값으로 사용되는 모든 데이터 타입은 반드시 
										WritableComparable 인터페이스를 구현해야 한다.
										--------------------------------------------------
										BooleanWritable	: Boolean
										ByteWritable	: 단일 byte
										DoubleWritable	: Double
										FloatWritable	: Float
										IntWritable		: Int
										LongWritable	: Long
										TextWritable	: UTF-8 형식의 문자열ㄹ
										NullWritable	: 데이터값이 필요없을 경우 사용
								
								- Mapper
										key와 value로 구성된 데이터를 전달받아 데이터를 가공하고 분리해 새로운 데이터 목록을 생성
										
								- Partitioner(선택 사항)
										맵 태스크의 출력 데이터가 어떤 리듀스 태스크로 전달될지 결정
								
								- Reducer
										맵 태스크의 출력데이터를 입력데이터로 전달받아 집계 연산 수행
										
								- Combiner
										Mapper의 출력 데이터를 입력 데이터 전달 받아 연산을 수행하며 shuffle 할 데이터의 크기를 줄일 경우 사용
								
								- Output Format
										TextOutputFormat : 텍스트 파일에 레코드를 출력할 때 사용
												key와 value의 구분자는 탭 문자를 사용
										SequenceFileOutputFormat : 
												
										SequenceFileAsBinaryOutputFromat : 
												
										FilterOutputFormat
										NullOutputFormat
						
						e) 코드 작성
								gedit input.txt
								----------------
								read a book
								write a book
								
								hdfs dfs -put input.txt /upload/input.txt
								hdfs dfs -ls /upload
								
										
								
								
								
								
								
								